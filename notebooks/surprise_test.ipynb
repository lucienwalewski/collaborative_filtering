{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from numba import jit, njit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/data_train.csv', index_col=0)\n",
    "\n",
    "# rename column and turn ot uint8\n",
    "data.rename(columns={'Prediction': 'Rating'}, inplace=True)\n",
    "data['Rating'] = data['Rating'].astype('uint8')\n",
    "\n",
    "# get user and movie id by splitting index given in format rX_cY\n",
    "data['UserId'] = data.index.str.split('_').str[0].str[1:].astype('int32')\n",
    "data['MovieId'] = data.index.str.split('_').str[1].str[1:].astype('int32')\n",
    "\n",
    "# subtract min UserId and MovieID to get indices starting at 0\n",
    "data['UserId'] = data['UserId'] - data['UserId'].min()\n",
    "data['MovieId'] = data['MovieId'] - data['MovieId'].min()\n",
    "\n",
    "# reorder columns to UserId, MovieId, Rating\n",
    "data = data[['UserId', 'MovieId', 'Rating']]\n",
    "\n",
    "# split into train and val data\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get sparse matrix from data given as a dataframe with row and column indices\n",
    "def get_sparse_matrix(data, n_rows, n_cols):\n",
    "    return csr_matrix((data['Rating'].values, (data['UserId'].values, data['MovieId'].values)), shape=(n_rows, n_cols))\n",
    "\n",
    "n_rows = train_data['UserId'].max() + 1 # might raise errors if in val set user with larger id\n",
    "n_cols = train_data['MovieId'].max() + 1 # might raise errors if in val set movie with larger id\n",
    "train_matrix = get_sparse_matrix(train_data, n_rows, n_cols)\n",
    "val_matrix = get_sparse_matrix(val_data, n_rows, n_cols)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, SVD, BaselineOnly, Reader, NormalPredictor, KNNBasic\n",
    "from surprise.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "train_dataset = Dataset.load_from_df(data[['UserId', 'MovieId', 'Rating']], reader)\n",
    "\n",
    "algo = SVD()\n",
    "# algo = KNNBasic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0274  1.0294  1.0279  1.0253  1.0286  1.0277  0.0014  \n",
      "MAE (testset)     0.8400  0.8409  0.8388  0.8370  0.8409  0.8395  0.0015  \n",
      "Fit time          96.14   29867.1899.78   103.99  102.19  6053.86 11906.66\n",
      "Test time         526.70  26745.90268.01  274.91  287.28  5620.56 10563.12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([1.02743206, 1.02941419, 1.02788003, 1.02525599, 1.02855448]),\n",
       " 'test_mae': array([0.83997464, 0.84089572, 0.83882355, 0.83704645, 0.84088354]),\n",
       " 'fit_time': (96.14492225646973,\n",
       "  29867.17919898033,\n",
       "  99.78141617774963,\n",
       "  103.98659014701843,\n",
       "  102.18910479545593),\n",
       " 'test_time': (526.6988308429718,\n",
       "  26745.90246105194,\n",
       "  268.01205801963806,\n",
       "  274.90552020072937,\n",
       "  287.2830331325531)}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_validate(algo, train_dataset, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
