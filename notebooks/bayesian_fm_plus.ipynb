{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-07-14T20:02:43.032229Z",
     "end_time": "2023-07-14T20:02:43.036066Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import metrics\n",
    "import myfm\n",
    "from myfm import RelationBlock\n",
    "from scipy import sparse as sps\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "def load_cil(dataset=\"split\"):\n",
    "\n",
    "    file = \"data_train\" if dataset != \"test\" else \"sampleSubmission\"\n",
    "    data = pd.read_csv(f'../data/{file}.csv', index_col=0)\n",
    "    data['user'] = data.index.str.split('_').str[0].str[1:].astype('int32')\n",
    "    data['movie'] = data.index.str.split('_').str[1].str[1:].astype('int32')\n",
    "    data.rename(columns={'Prediction': 'rating'}, inplace=True)\n",
    "    data['rating'] = data['rating'].astype('uint8')\n",
    "    data = data[['user', 'movie', 'rating']]\n",
    "\n",
    "    data['user'] = data['user']\n",
    "    data['movie'] = data['movie']\n",
    "    # print(\"Subtracted {} from user and movie\".format(1))\n",
    "\n",
    "    user_num = 10000  # int(data['user'].max() + 1)\n",
    "    movie_num = 1000  # int(data['movie'].max() + 1)\n",
    "    print(\"User num: {}, Movie num: {}\".format(user_num, movie_num))\n",
    "\n",
    "    train_data = val_data = None\n",
    "    if dataset == \"test\":\n",
    "        val_data = data\n",
    "    elif dataset == \"train\":\n",
    "        train_data = data\n",
    "    else:\n",
    "        train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "    return train_data, val_data, user_num, movie_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User num: 10000, Movie num: 1000\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data, user_num, movie_num = load_cil(\"train\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-14T20:02:48.170959Z",
     "end_time": "2023-07-14T20:02:51.254321Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User num: 10000, Movie num: 1000\n"
     ]
    }
   ],
   "source": [
    "_, val_data, user_num, movie_num = load_cil(\"test\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-14T20:02:53.199839Z",
     "end_time": "2023-07-14T20:02:56.430442Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "# index \"0\" is reserved for unknown ids.\n",
    "user_to_index = defaultdict(lambda : 0, { uid: i+1 for i,uid in enumerate(np.unique(train_data.user)) })\n",
    "movie_to_index = defaultdict(lambda: 0, { mid: i+1 for i,mid in enumerate(np.unique(train_data.movie))})\n",
    "USER_ID_SIZE = len(user_to_index) + 1\n",
    "MOVIE_ID_SIZE = len(movie_to_index) + 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-14T20:02:58.352918Z",
     "end_time": "2023-07-14T20:02:58.408873Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "# The flags to control the included features.\n",
    "use_iu = True # use implicit user feature\n",
    "use_ii = True # use implicit item feature\n",
    "\n",
    "movie_vs_watched = dict()\n",
    "user_vs_watched = dict()\n",
    "for row in train_data.itertuples():\n",
    "    user_id = row.user\n",
    "    movie_id = row.movie\n",
    "    movie_vs_watched.setdefault(movie_id, list()).append(user_id)\n",
    "    user_vs_watched.setdefault(user_id, list()).append(movie_id)\n",
    "X_date_train, X_date_test = (None, None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-14T20:03:02.476616Z",
     "end_time": "2023-07-14T20:03:03.171994Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "# given user/movie ids, add additional infos and return it as sparse\n",
    "def augment_user_id(user_ids):\n",
    "    Xs = []\n",
    "    X_uid = sps.lil_matrix((len(user_ids), USER_ID_SIZE))\n",
    "    for index, user_id in enumerate(user_ids):\n",
    "        X_uid[index, user_to_index[user_id]] = 1\n",
    "    Xs.append(X_uid)\n",
    "    if use_iu:\n",
    "        X_iu = sps.lil_matrix((len(user_ids), MOVIE_ID_SIZE))\n",
    "        for index, user_id in enumerate(user_ids):\n",
    "            watched_movies = user_vs_watched.get(user_id, [])\n",
    "            normalizer = 1 / max(len(watched_movies), 1) ** 0.5\n",
    "            for uid in watched_movies:\n",
    "                X_iu[index, movie_to_index[uid]] = normalizer\n",
    "        Xs.append(X_iu)\n",
    "    return sps.hstack(Xs, format='csr')\n",
    "\n",
    "def augment_movie_id(movie_ids):\n",
    "    Xs = []\n",
    "    X_movie = sps.lil_matrix((len(movie_ids), MOVIE_ID_SIZE))\n",
    "    for index, movie_id in enumerate(movie_ids):\n",
    "        X_movie[index, movie_to_index[movie_id]] = 1\n",
    "    Xs.append(X_movie)\n",
    "\n",
    "    if use_ii:\n",
    "        X_ii = sps.lil_matrix((len(movie_ids), USER_ID_SIZE))\n",
    "        for index, movie_id in enumerate(movie_ids):\n",
    "            watched_users = movie_vs_watched.get(movie_id, [])\n",
    "            normalizer = 1 / max(len(watched_users), 1) ** 0.5\n",
    "            for uid in watched_users:\n",
    "                X_ii[index, user_to_index[uid]] = normalizer\n",
    "        Xs.append(X_ii)\n",
    "\n",
    "\n",
    "    return sps.hstack(Xs, format='csr')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-14T20:03:07.943791Z",
     "end_time": "2023-07-14T20:03:07.946914Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "train_uid_unique, train_uid_index = np.unique(train_data.user, return_inverse=True)\n",
    "train_mid_unique, train_mid_index = np.unique(train_data.movie, return_inverse=True)\n",
    "user_data_train = augment_user_id(train_uid_unique)\n",
    "movie_data_train = augment_movie_id(train_mid_unique)\n",
    "\n",
    "test_uid_unique, test_uid_index = np.unique(val_data.user, return_inverse=True)\n",
    "test_mid_unique, test_mid_index = np.unique(val_data.movie, return_inverse=True)\n",
    "user_data_test = augment_user_id(test_uid_unique)\n",
    "movie_data_test = augment_movie_id(test_mid_unique)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-14T20:03:11.868197Z",
     "end_time": "2023-07-14T20:03:19.903699Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "block_user_train = RelationBlock(train_uid_index, user_data_train)\n",
    "block_movie_train = RelationBlock(train_mid_index, movie_data_train)\n",
    "block_user_test = RelationBlock(test_uid_index, user_data_test)\n",
    "block_movie_test = RelationBlock(test_mid_index, movie_data_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-14T20:03:25.722221Z",
     "end_time": "2023-07-14T20:03:25.723675Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "y_train = train_data.rating.values\n",
    "y_test = val_data.rating.values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-14T20:05:05.840526Z",
     "end_time": "2023-07-14T20:05:05.845585Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "FM_RANK = 10\n",
    "N_ITER = 512\n",
    "N_KEPT_SAMPLES = 200"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-14T20:05:13.456725Z",
     "end_time": "2023-07-14T20:05:13.462417Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alpha = 1.13 w0 = 3.61 : 100%|██████████| 512/512 [03:55<00:00,  2.17it/s]\n"
     ]
    }
   ],
   "source": [
    "fm_rb = myfm.MyFMRegressor(rank=FM_RANK).fit(\n",
    "    X_date_train, y_train,\n",
    "    X_rel=[block_user_train, block_movie_train],\n",
    "    group_shapes=[USER_ID_SIZE, MOVIE_ID_SIZE, MOVIE_ID_SIZE, USER_ID_SIZE],\n",
    "    n_iter=N_ITER, n_kept_samples=N_KEPT_SAMPLES\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-14T20:05:29.229003Z",
     "end_time": "2023-07-14T20:09:25.030163Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "test_prediction = fm_rb.predict(\n",
    "    X_date_test,\n",
    "    X_rel=[block_user_test, block_movie_test]\n",
    ")\n",
    "val_data['Prediction'] = test_prediction"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-14T20:12:38.227277Z",
     "end_time": "2023-07-14T20:12:38.228607Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse=0.973083165848429, mae=0.7761185158641162\n"
     ]
    }
   ],
   "source": [
    "rmse = ((y_test - test_prediction) ** 2).mean() ** 0.5\n",
    "mae = np.abs(y_test - test_prediction).mean()\n",
    "print(f'rmse={rmse}, mae={mae}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-14T20:01:13.014910Z",
     "end_time": "2023-07-14T20:01:13.019270Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 512, 50 ->  rmse=0.9774482247691249\n",
    "# 512, 10 -> rmse=0.975..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "val_data['Prediction'].to_csv(f\"../lightning_logs/BFM/predictions_bfm_plus_plus_grouped.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-14T20:12:40.554048Z",
     "end_time": "2023-07-14T20:12:41.605040Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Investigate std of predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "# get all predictions\n",
    "\n",
    "def get_prediction_matrix(fm_rb):\n",
    "    number_of_samples = fm_rb.w0_samples.shape[0]\n",
    "    prediction_matrix_samples = np.zeros((number_of_samples, 10000, 1000))\n",
    "    for sample in range(fm_rb.w0_samples.shape[0]):\n",
    "        # make all shape 10000 x 1000\n",
    "        w0 = np.ones((10000, 1000)) * fm_rb.w0_samples[sample]\n",
    "\n",
    "        user_bias = fm_rb.w_samples[sample][:10000]\n",
    "        user_bias = np.repeat(user_bias, 1000).reshape(10000, 1000)\n",
    "\n",
    "        movie_bias = fm_rb.w_samples[sample][10000:]\n",
    "        movie_bias = np.tile(movie_bias, 10000).reshape(10000, 1000)\n",
    "\n",
    "        interaction = np.dot(fm_rb.V_samples[sample][:10000], fm_rb.V_samples[sample][10000:].T)\n",
    "\n",
    "        prediction_matrix_samples[sample] = w0 + user_bias + movie_bias + interaction\n",
    "    return prediction_matrix_samples\n",
    "\n",
    "# get single prediction\n",
    "def make_prediction(fm_rb, user, movie, watched_movies, interested_users):\n",
    "    predictions = []\n",
    "    for i in range(2): # range(fm_rb.w0_samples.shape[0]):\n",
    "        w0 = fm_rb.w0_samples[i]\n",
    "        user_bias = fm_rb.w_samples[i][user]\n",
    "        movie_bias = fm_rb.w_samples[i][10001 + 1001 + movie]\n",
    "        u = fm_rb.V_samples[i][user]\n",
    "        v = fm_rb.V_samples[i][10001 + 1001 + movie]\n",
    "\n",
    "        movie_sum = 0\n",
    "        for j in watched_movies:\n",
    "            v_j = fm_rb.V_samples[i][10001 + j]\n",
    "            movie_sum += np.dot(v, v_j)\n",
    "        movie_sum /= np.sqrt(len(watched_movies))\n",
    "\n",
    "        user_sum = 0\n",
    "        for j in interested_users:\n",
    "            u_j = fm_rb.V_samples[i][10001 + 1001 + 1001 + j]\n",
    "            user_sum += np.dot(u, u_j)\n",
    "        user_sum /= np.sqrt(len(interested_users))\n",
    "\n",
    "        prediction = w0 + user_bias + movie_bias + np.dot(u, v) + movie_sum + user_sum\n",
    "        predictions.append(prediction)\n",
    "    prediction = np.mean(predictions)\n",
    "    std = np.std(predictions)\n",
    "    return prediction, std\n",
    "\n",
    "# this will be more complicated as now\n",
    "# w0_samples is of shape (200,)\n",
    "# w_samples is of shape (200, 22004)\n",
    "# V_samples is of shape (200, 22004, 10)\n",
    "# have to find out what exactly Bayesian formula is"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-14T21:04:34.816308Z",
     "end_time": "2023-07-14T21:04:34.824668Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "data": {
      "text/plain": "(37, 1, 3, 3.279220736846226)"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data['user'][0], val_data['movie'][0], val_data['rating'][0], val_data['Prediction'][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-14T20:44:55.567842Z",
     "end_time": "2023-07-14T20:44:55.571818Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "data": {
      "text/plain": "(2.1946875576300475, 0.42387251073583576)"
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item = 0\n",
    "watched_movies = user_data_test[test_uid_index[item]].nonzero()[1][1:] - 10001\n",
    "interested_users = movie_data_test[test_mid_index[item]].nonzero()[1][1:] - 1001\n",
    "make_prediction(fm_rb, val_data['user'][item], val_data['movie'][item], watched_movies, interested_users)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-14T21:04:36.474094Z",
     "end_time": "2023-07-14T21:05:28.601506Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
